# VXNAT-based pulmonary x-ray prediction program for pneumonia patients.

## **‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô**

Status :

    ‚úÖ = Clear
    üìå = In progress
    ‚ÅâÔ∏è = Something wrong
|       | Topics                                                                                                                                                                                                                                                                                                                                                                              | Percent                               | Status |
| ----- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------- | ------ |
| **1** | **‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å class ‡∏ö‡∏ô vxnat**<br><br>- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏•‡∏±‡πä‡∏Å‡∏≠‡∏¥‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å class ‡∏ö‡∏ô vxnat<br>- ‡∏õ‡∏•‡∏±‡πä‡∏Å‡∏≠‡∏¥‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ convert DICOM to JPEG ‡πÑ‡∏î‡πâ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ training                                                                                                                                                                                                       | 100%                                  | ‚úÖ      |
| **2** | **‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô REST API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ download ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å xnat**<br><br>- ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ download ‡∏†‡∏≤‡∏û‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô REST API<br>- ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å class ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÑ‡∏õ training<br><br>Train<br><br>    |-normal<br>    |-pneumonia<br><br>Val<br><br>    |-normal<br>    |-pneumonia<br><br>Test<br><br>    |-normal<br>    |-pneumonia                                | 100%                                  | ‚úÖ      |
| **3** | **‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£ training ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏à‡∏≤‡∏Å vxnat** <br><br>- ‡πÉ‡∏ä‡πâ Tensorflow  framework<br>- ‡πÉ‡∏ä‡πâ Resnet50 ‡πÄ‡∏õ‡πá‡∏ô model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ test <br>- ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ save model ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô version ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£<br><br>‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£ upload model ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏ö‡∏ô google drive ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏∞‡∏î‡∏ß‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô<br><br>- ‡πÉ‡∏ä‡πâ google drive api ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ upload                                         | 100% <br><br><br><br><br>        100% | ‚úÖ      |
| **4** | **‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£ download model ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô**<br><br>- ‡πÉ‡∏ä‡πâ google drive api ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ download<br>- ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå model ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£ upload<br><br>**‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á AI ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡πÇ‡∏£‡∏Ñ Pneumonia ‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏π‡∏õ‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå**<br><br>- ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ model ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ download ‡∏°‡∏≤<br>- ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ú‡∏•‡∏†‡∏≤‡∏û ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô DICOM ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏™‡πà Puttext | 100% <br><br><br><br>        100%     | ‚úÖ      |
| **5** | **‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏•‡∏±‡πä‡∏Å‡∏≠‡∏¥‡∏ô AI service ‡∏ö‡∏ô vxnat**<br><br>- ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á scan ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ rest api ‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÄ‡∏Å‡πá‡∏ö<br><br>**‡πÅ‡∏û‡πá‡∏Ñ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏õ‡πá‡∏ô docker image ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏•‡∏±‡πä‡∏Å‡∏≠‡∏¥‡∏ô‡∏ö‡∏ô xnat** <br><br>- build docker image<br>- ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á docker ‡∏Å‡∏±‡∏ö vxnat ‡∏î‡πâ‡∏ß‡∏¢ json file<br>- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô                                                            | 100% <br><br><br>        100%         | ‚úÖ      |
| **6** | **‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°**<br><br>- ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô<br><br>**‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô**                                                                                                                                                                                                                                                                          | 100% <br><br><br>        100%         | üìå     |



# **Technical Report**

**Demo Video :**

https://www.youtube.com/watch?v=HDvdCnHQDgc&


[https://youtu.be/HDvdCnHQDgc](https://youtu.be/HDvdCnHQDgc)

 **Flow diagram :**

![](https://paper-attachments.dropboxusercontent.com/s_7787865C7FAB426CF3D08B3DFD1DC042F998D51D6B0FF1E674EE2778F2C8DB49_1684767709723_project-Page-1.drawio+3.png)


 
 
 ‡∏à‡∏≤‡∏Å Flow diagram ‡∏à‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô XNAT Machine Learning ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô Flow diagram ‡πÄ‡∏î‡∏¥‡∏° ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô XNAT Machine Learning ‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ñ‡πà‡∏≠‡∏¢‡∏Ç‡πâ‡∏≤‡∏á‡∏¢‡∏≤‡∏Å ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏à‡∏∞ training model ‡∏Ñ‡πà‡∏≠‡∏¢‡∏Ç‡πâ‡∏≤‡∏á‡πÄ‡∏¢‡∏≠‡∏∞ ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á XNAT Machine Learning ‡∏≠‡∏≠‡∏Å‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ 
 
‡∏ú‡∏°‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡∏ï‡∏≤‡∏° Flow diagram ‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1 

![](https://paper-attachments.dropboxusercontent.com/s_7787865C7FAB426CF3D08B3DFD1DC042F998D51D6B0FF1E674EE2778F2C8DB49_1684767735193_project-Page-1.drawio+6.png)


‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1 ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô VXNAT ‡πÇ‡∏î‡∏¢‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ train ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡∏ú‡∏°‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ OHIF-XNAT Viewer ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ label ‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ú‡∏°‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô XNAT Machine Learning ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ï‡πà‡∏ú‡∏°‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏°‡∏±‡∏ô basic ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô classification ‡πÅ‡∏ó‡∏ô ‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™ ‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á plugin ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÉ‡∏ä‡πâ run ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡∏≤‡∏î‡∏±‡∏á‡∏£‡∏π‡∏õ

![](https://paper-attachments.dropboxusercontent.com/s_7787865C7FAB426CF3D08B3DFD1DC042F998D51D6B0FF1E674EE2778F2C8DB49_1683616024979_Screenshot+from+2023-05-09+14-06-02.png)


‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ú‡∏°‡∏à‡∏∞‡πÉ‡∏´‡πâ user ‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏™‡πà‡πÄ‡∏•‡∏Ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏•‡∏≤‡∏™ ‡πÇ‡∏î‡∏¢‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏ Required ‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ß‡πà‡∏≤ 0 = Normal, 1 = Pneumonia ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏£‡∏ñ‡πÉ‡∏™‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏Ñ‡πà 0  ‡∏´‡∏£‡∏∑‡∏≠ 1 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô 
‡∏û‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡∏Ñ‡∏•‡∏≤‡∏™‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î Run Container ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß plugin ‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á DICOM ‡πÄ‡∏õ‡πá‡∏ô JPEG ‡πÇ‡∏î‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ save ‡∏£‡∏π‡∏õ‡πÄ‡∏õ‡πá‡∏ô JPEG ‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ó‡πâ‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡∏î‡∏±‡∏á‡∏£‡∏π‡∏õ

![](https://paper-attachments.dropboxusercontent.com/s_7787865C7FAB426CF3D08B3DFD1DC042F998D51D6B0FF1E674EE2778F2C8DB49_1683616422248_Screenshot+from+2023-05-09+14-13-25.png)


‡πÅ‡∏•‡∏∞‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á VXNAT ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏Ñ‡∏£‡∏±‡∏ö
‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π code ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å :
https://github.com/anantachai352/ai-service-on-xnat-project/tree/main/Class_label


----------

‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ training 

![](https://paper-attachments.dropboxusercontent.com/s_7787865C7FAB426CF3D08B3DFD1DC042F998D51D6B0FF1E674EE2778F2C8DB49_1684767753371_project-Page-1.drawio+7.png)


‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô python ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **REST API** ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å VXNAT server ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ JPEG ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏Ñ‡∏£‡∏±‡∏ö ‡∏î‡∏±‡∏á‡∏†‡∏≤‡∏û diagram ‡∏Ñ‡∏£‡∏±‡∏ö

![](https://paper-attachments.dropboxusercontent.com/s_7787865C7FAB426CF3D08B3DFD1DC042F998D51D6B0FF1E674EE2778F2C8DB49_1683617832856_api.drawio.png)


‡πÉ‡∏ô Project ‡∏Ç‡∏≠‡∏á VXNAT ‡∏à‡∏∞‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢ Subject ‡πÅ‡∏•‡∏∞‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Subject ‡∏Å‡πá‡∏à‡∏∞‡∏°‡∏µ Session ‡πÅ‡∏•‡∏∞ Scan ‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡πÉ‡∏ô‡∏™‡∏∏‡∏î‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà Project ID ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏†‡∏≤‡∏û JPEG ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Project ‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á Project ‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÇ‡∏î‡∏¢‡∏ú‡∏°‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÄ‡∏Å‡πá‡∏¢‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô Train 70%, Validation 15% ‡πÅ‡∏•‡∏∞ Test 15% 

‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏à‡∏∞‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡∏≠‡∏µ‡∏Å ‡∏Å‡πá‡∏Ñ‡∏∑‡∏≠ normal ‡πÅ‡∏•‡∏∞ pneumonia ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö
Train        70%

    |-normal
    |-pneumonia

Val           15%

    |-normal
    |-pneumonia

Test          15%

    |-normal
    |-pneumonia

‡πÇ‡∏î‡∏¢‡∏ú‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô 0 ‡∏Å‡∏±‡∏ö 1 ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏õ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ñ‡∏£‡∏±‡∏ö ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Å‡πá‡∏à‡∏∞‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏ú‡∏°‡∏Ñ‡∏£‡∏±‡∏ö
‡πÇ‡∏î‡∏¢‡∏ú‡∏°‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á **code** ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ 

**‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1 :** 

    def api_images_from_xnat(xnat_url, user, password, project_id):
        folder = 'Zipdata'
        os.makedirs(folder, exist_ok=True)
        
    
        # Authenticate with the XNAT server and get the JSESSIONID cookie
        auth_url = f'http://{xnat_url}/data/JSESSION'
        auth_response = requests.post(auth_url, auth=(user, password))
        jsessionid = auth_response.cookies.get('JSESSIONID')
    
    
        # Get all subjects for the project
        subjects_url = f'http://{xnat_url}/data/archive/projects/{project_id}/subjects'
        response = requests.get(subjects_url, cookies={'JSESSIONID': jsessionid}, stream=True)
        subjects_json = response.json()
    
        print(f'Loading images from {project_id}...')
    
        # print(subjects_json)
        # Loop through all subjects and download DICOM files
        for subject in subjects_json\['ResultSet'\]['Result']:
    
            subject_id = subject['ID']
            # print(subject_label)
            subject_sessions_url = f"http://{xnat_url}/data/projects/{project_id}/subjects/{subject_id}/experiments"
            response = requests.get(subject_sessions_url, cookies={'JSESSIONID': jsessionid}, stream=True)
            subject_sessions_json = response.json()
            # print(subject_sessions_json)
            for session in subject_sessions_json\['ResultSet'\]['Result']:
                session_id = session['ID']
                # print(session_id)
                session_scans_url = f"http://{xnat_url}/data/experiments/{session_id}/scans"
                response = requests.get(session_scans_url, cookies={'JSESSIONID': jsessionid}, stream=True)
                session_scans_json = response.json()
                # print(session_scans_json)
                for scan in session_scans_json\['ResultSet'\]['Result']:
                    scan_id = scan['ID']
                    # print(scan_id)
                    scan_files_url = f"http://{xnat_url}/data/archive/projects/{project_id}/subjects/{subject_id}/experiments/{session_id}/scans/{scan_id}/resources/pneumonia_label/files?format=zip"
                    response = requests.get(scan_files_url, cookies={'JSESSIONID': jsessionid}, stream=True)
                    # print(response)
                    zip_file = os.path.join(folder, f"{subject_id}.zip") 
                    with open(zip_file, 'wb') as f:
                        f.write(response.content)
                    
                    # with zipfile.ZipFile(zip_file) as zf:
                    #     print(zf.namelist)
        return folder

‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***api_images_from_xnat***  ****‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ REST API ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ download ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å VXNAT ‡πÇ‡∏î‡∏¢‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ url, user, password ‡πÅ‡∏•‡∏∞ project id ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ú‡∏°‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ download ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á project ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏µ‡∏¢‡∏á project id ‡∏Å‡πá‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ download 

    ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ download ‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***api_images_from_xnat***  ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå ***Zip*** ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏ú‡∏•‡∏à‡∏∂‡∏á

‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ folder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå Zip ‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ ***return*** ‡∏ä‡∏∑‡πà‡∏≠ folder ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ

**‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2 :**

    def unzip(zip_folder):
        class1 = 'normal'
        class2 = 'pneumonia'
    
        #Create 3 folders
        folder1 = 'train'
        folder2 = 'val'
        folder3 = 'test'
    
        folder_paths = [folder1, folder2, folder3]
    
        for folder_path in folder_paths:
            if os.path.exists(folder_path) and os.path.isdir(folder_path):
                shutil.rmtree(folder_path)
                print(f"{folder_path} has been deleted.")
            else:
                print(f"{folder_path} could not be deleted because it is not a folder or does not exist.")
    
    
        os.makedirs(folder1, exist_ok=True)
        os.makedirs(os.path.join(folder1, class1), exist_ok=True)
        os.makedirs(os.path.join(folder1, class2), exist_ok=True)
    
        os.makedirs(folder2, exist_ok=True)
        os.makedirs(os.path.join(folder2, class1), exist_ok=True)
        os.makedirs(os.path.join(folder2, class2), exist_ok=True)
    
        os.makedirs(folder3, exist_ok=True)
        os.makedirs(os.path.join(folder3, class1), exist_ok=True)
        os.makedirs(os.path.join(folder3, class2), exist_ok=True)
    
        # Read all image filenames from a folder
        files = os.listdir(zip_folder)
        # print(files)
    
        # Random files and divide them into groups based on a certain percentage
        random.shuffle(files)
        total_files = len(files)
        # print(total_files)
        folder1_files = files[:int(total_files*0.7)]
        # print(folder1_files)
        folder2_files = files[int(total_files*0.7):int(total_files*0.85)]
        # print(folder2_files)
        folder3_files = files[int(total_files*0.85):]
        # print(folder3_files)
    
        count_1 = 0
        count_2 = 0
        count_3 = 0 
    
        ## For the train folder
        for files in folder1_files:
            count_1 += 1
            # print(files)
            zip_file = zipfile.ZipFile(zip_folder + '/' +files, 'r')
            # print(zip_file)
            
            for file_list in zip_file.namelist():
                # print(file_list)
                filename = os.path.basename(f'{file_list}')
                print(filename)
                if file_list.endswith('0.jpeg'):
                    image_data = zip_file.read(file_list)
                    # save images
                    with open(folder1 + '/' + class1 + '/' + filename, 'wb') as image_file:
                        image_file.write(image_data)
                    
                elif file_list.endswith('1.jpeg'):
                    image_data = zip_file.read(file_list)
                    # save images
                    with open(folder1 + '/' + class2 + '/' + filename, 'wb') as image_file:
                        image_file.write(image_data)
                        
            zip_file.close()
    
    
        ## For the validation folder
        for files in folder2_files:
            count_2 += 1
            # print(files)
            zip_file = zipfile.ZipFile(zip_folder + '/' +files, 'r')
            # print(zip_file)
            
    
            for file_list in zip_file.namelist():
                # print(file_list)
                filename = os.path.basename(f'{file_list}')
                print(filename)
                if file_list.endswith('0.jpeg'):
                    image_data = zip_file.read(file_list)
                    # save images
                    with open(folder2 + '/' + class1 + '/' + filename, 'wb') as image_file:
                        image_file.write(image_data)
                    
                elif file_list.endswith('1.jpeg'):
                    image_data = zip_file.read(file_list)
                    # save images
                    with open(folder2 + '/' + class2 + '/' + filename, 'wb') as image_file:
                        image_file.write(image_data)
                        
            zip_file.close()
        
    
        ## For the test folder
        for files in folder3_files:
            count_3 += 1
            # print(files)
            zip_file = zipfile.ZipFile(zip_folder + '/' +files, 'r')
            # print(zip_file)
            
            for file_list in zip_file.namelist():
                # print(file_list)
                filename = os.path.basename(f'{file_list}')
                print(filename)
                if file_list.endswith('0.jpeg'):
                    image_data = zip_file.read(file_list)
                    # save images
                    with open(folder3 + '/' + class1 + '/' + filename, 'wb') as image_file:
                        image_file.write(image_data)
                    
                elif file_list.endswith('1.jpeg'):
                    image_data = zip_file.read(file_list)
                    # save images
                    with open(folder3 + '/' + class2 + '/' + filename, 'wb') as image_file:
                        image_file.write(image_data)
                        
            zip_file.close()
        
        num = count_1 + count_2 + count_3
        print('Total files : ', num)
        print(f'Train : ', count_1)
        print(f'Validataion : ', count_2)
        print(f'Test : ', count_3)

‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***unzip*** ‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Zip ‡∏°‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ï‡∏≤‡∏° folder ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡∏°‡∏µ 3 ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πà train, val ‡πÅ‡∏•‡∏∞ test ‡πÇ‡∏î‡∏¢‡∏°‡∏µ‡∏≠‡∏±‡∏ï‡∏ï‡∏£‡∏≤‡∏™‡πà‡∏ß‡∏ô 70-15-15 ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö ‡πÇ‡∏î‡∏¢‡πÉ‡∏ô‡πÅ‡∏ö‡πà‡∏á‡∏†‡∏≤‡∏û‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏∏‡πà‡∏°‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ 

    ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏û‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á ***Class*** ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô normal ‡∏Å‡∏±‡∏ö pneumonia ‡πÇ‡∏î‡∏¢

‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ‡∏´‡∏•‡∏±‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏π‡∏õ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏≠‡∏∞‡πÑ‡∏£ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç 0 ‡∏à‡∏∞‡πÅ‡∏¢‡∏Å‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á normal ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç 1 ‡∏à‡∏∞‡πÅ‡∏¢‡∏Å‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á pneumonia 

    ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏Å‡πá‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏ö‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ download ‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢ REST API ‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏†‡∏≤‡∏û dataset ‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÑ‡∏õ training ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™


----------

‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£ **Training** ‡∏Ñ‡∏£‡∏±‡∏ö

![](https://paper-attachments.dropboxusercontent.com/s_7787865C7FAB426CF3D08B3DFD1DC042F998D51D6B0FF1E674EE2778F2C8DB49_1684767770805_project-Page-1.drawio+8.png)


‡πÇ‡∏î‡∏¢‡∏ú‡∏°‡∏à‡∏à‡∏∞‡πÉ‡∏ä‡πâ tensorflow ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ train ‡∏Ñ‡∏£‡∏±‡∏ö ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÅ‡∏¢‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÑ‡∏ß‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡πá‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏∞‡∏ö‡∏∏ path ‡πÅ‡∏•‡πâ‡∏ß‡∏ô‡∏≥‡∏°‡∏≤ train ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏ú‡∏°‡∏à‡∏∞‡πÉ‡∏ä‡πâ resnet50 ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ train ‡∏Ñ‡∏£‡∏±‡∏ö
‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ú‡∏°‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ upload model ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á google drive ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö model ‡∏ö‡∏ô‡∏Ñ‡∏•‡∏≤‡∏ß‡∏î‡πå ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏µ‡∏≠‡∏Å‡πÉ‡∏ä‡πâ model ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà‡∏ñ‡πâ‡∏≤‡∏°‡∏µ internet ‡πÇ‡∏î‡∏¢‡∏ú‡∏°‡∏à‡∏∞‡πÅ‡∏ö‡πà‡∏á code ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ 
**‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1 :**

    # Configure for image resizing and augmentation
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True
    )
    
    # Generator for train set
    train = train_datagen.flow_from_directory(
        train_dir,
        target_size=image_size,
        batch_size=batch_size,
        shuffle = True,
        class_mode='categorical'
    )
    
    
    # Configure image scaling for validation set and test set
    val_datagen = ImageDataGenerator(rescale=1./255)
    test_datagen = ImageDataGenerator(rescale=1./255)
    
    # Generator for validation set
    val = val_datagen.flow_from_directory(
        val_dir,
        target_size=image_size,
        batch_size=batch_size,
        shuffle = True,
        class_mode='categorical'
    )
    
    # Generator for test set
    test = test_datagen.flow_from_directory(
        test_dir,
        target_size=image_size,
        batch_size=batch_size,
        shuffle = True,
        class_mode='categorical'
    )
    
    resize_and_rescale = tf.keras.Sequential([
      layers.Resizing(224, 224),
      layers.Rescaling(1./255)
    ])
    
    data_augmentation = tf.keras.Sequential([
      layers.RandomFlip("horizontal"),
      layers.RandomRotation(0.2),
    ])
    
    class_names = list(train.class_indices.keys())
    print(class_names)
    
    
    class Resnet50Model(tf.Module):
        def __init__(self, num_classes=10):
            super(Resnet50Model, self).__init__()
            self.pretrained_model = tf.keras.applications.ResNet50(include_top=False,
                                                                   input_shape=(224, 224, 3),
                                                                   pooling='avg')
            for layer in self.pretrained_model.layers:
                resize_and_rescale,
                data_augmentation,
                layer.trainable = True   
            self.flatten = Flatten()
            self.fc1 = Dense(512, activation='relu')
            self.fc2 = Dense(num_classes, activation='softmax')
        
        def __call__(self, inputs):
            x = self.pretrained_model(inputs)
            x = self.flatten(x)
            x = self.fc1(x)
            x = self.fc2(x)
            return x
    
    inputs = tf.keras.Input(shape=(224, 224, 3))
    resnet50_layer = Resnet50Model(num_classes=num_classes)
    outputs = resnet50_layer(inputs)
    model = Model(inputs=inputs, outputs=outputs)
    
    # Set Early stopping
    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    
    # compile ‡πÅ‡∏•‡∏∞ train model
    model.compile(optimizer = Adam(learning_rate = learning_rate), loss='categorical_crossentropy', metrics=['accuracy'], run_eagerly=True)
    model.summary()
    history = model.fit(
                train,
                steps_per_epoch=train.n // train.batch_size,
                epochs=epochs,
                validation_data=val,
                validation_steps=val.n // val.batch_size,
                shuffle=True,
                callbacks=[early_stopping]
    )
    ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ***training*** ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ú‡∏°‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞ class ‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏≠‡∏£‡πå dataset ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£

‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***unzip*** ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***flow_from_directory()*** ‡∏Ç‡∏≠‡∏á tensorflow ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏• ***train, val*** ‡πÅ‡∏•‡∏∞ ***test*** ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Resnet50 model ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ training ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***EarlyStopping()*** ‡∏Ç‡∏≠‡∏á tensorflow ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£ training ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Ñ‡πà‡∏≤ ***validataion loss*** ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡πá‡∏à‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ training 

**‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2 :**

    def save_model():
        # Create folder
        folder = 'model'
        os.makedirs(folder, exist_ok=True)
    
        # file name
        filename = 'pneumoniaRESNET50_v'
        file_extension = '.h5'
        i = 1
    
        while os.path.isfile(os.path.join(folder, f"{filename}{i}{file_extension}")):
            i += 1
        filepath = os.path.join(folder, f"{filename}{i}{file_extension}")
        filename = f"{filename}{i}{file_extension}"
    
        # save model 
        model.save(filepath)
    
        return folder, filename
    
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***save_model*** ‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ save model ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡∏∑‡πà‡∏≠ model ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå

‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ save ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠ model ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏•‡∏Ç‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡πÄ‡∏£‡∏∑‡πà‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏ó‡∏µ‡πà 1 

    ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö  version ‡∏Ç‡∏≠‡∏á model ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ñ‡∏∂‡∏á model ‡∏ó‡∏±‡∏ö‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡∏°‡∏µ

‡∏≠‡∏¢‡∏π‡πà‡∏Å‡πà‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß 

**‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 3 :** 

    def uploadFile(folder, filename):
        CLIENT_SECRET_FILE = 'client_secret_75469628766-mcsp2blgek6u9g587sl6dsani4ekvpao.apps.googleusercontent.com.json'
        API_NAME = 'drive'
        API_VERSION = 'v3'
        SCOPES = ['https://www.googleapis.com/auth/drive']
    
        service = Create_Service(CLIENT_SECRET_FILE, API_NAME, API_VERSION, SCOPES)
    
        # Upload File
        folder_id = '1kDl7wfNCSZcTJkIboqLk4tU1g72G9TC2'
        file_name = filename
        mime_type = 'application/x-hdf5'
    
        file_metadata = {
            'name': file_name,
            'parents': [folder_id]
        }
        file_size = os.path.getsize(f'{folder}/{filename}')
        # print(file_size)
    
    
        media = MediaFileUpload(f'{folder}/{file_name}', mimetype=mime_type, resumable=True, chunksize=1024*1024)
        http = httplib2.Http(timeout=600) 
    
        request = service.files().create(media_body=media, body=file_metadata, fields='id')
        progress_bar = tqdm(total=file_size, desc='Uploading', unit='bytes')
        response = None 
        start_time = time.time()
    
        while response is None:
             status, response = request.next_chunk()
             if status:
                uploaded_size = status.resumable_progress
                upload_speed = uploaded_size / (time.time() - start_time)
                time_left = (file_size - uploaded_size) / upload_speed
                progress_bar.set_postfix({'Speed': f'{upload_speed:.2f} bytes/s', 'Time Left': f'{time_left:.2f} seconds'})
                progress_bar.update(uploaded_size - progress_bar.n)
             time.sleep(0.1)
    
        progress_bar.close()
        print('Upload complete.')
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***uploadFile*** ‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î model ‡πÑ‡∏õ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà google drive ‡πÇ‡∏î‡∏¢‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á

‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡πÇ‡∏Ñ‡πä‡∏î‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á ***CLIENT_SECRET_FILE*** ‡∏ã‡∏∂‡πà‡∏á‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå ***token*** ‡∏Ç‡∏≠‡∏á google drive api ‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏Ç‡∏≠‡∏á json ‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏£‡∏±‡∏ö token ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å https://developers.google.com/drive/api/guides/about-sdk

    ‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2 ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏∑‡∏≠ folder id ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ

‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏ö‡∏ô google drive ‡∏Å‡πà‡∏≠‡∏ô ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô google drive ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ generate ****folder id ‡∏°‡∏≤‡πÉ‡∏´‡πâ ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ô‡∏±‡πâ‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏π‡∏ó‡∏µ‡πà ***URL*** ‡∏Å‡πá‡∏à‡∏∞‡∏û‡∏ö‡∏Å‡∏±‡∏ö folder id

    ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏™‡πà‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ upload model ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á google drive ‡πÑ‡∏î‡πâ ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏‡∏ó‡∏µ‡πà

‡∏≠‡∏¢‡∏π‡πà model ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ upload ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏Å‡πá‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ upload ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏ä‡∏±‡πà‡∏ô ***MediaFileUpload*** ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ upload ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å google ‡∏à‡∏∞‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ login google ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô ‡∏à‡∏∞‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ***token_drive_v3.pickle*** ‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ login ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏≠‡∏µ‡∏Å

‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π code ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å :
https://github.com/anantachai352/ai-service-on-xnat-project/tree/main/Downloadandtraining


----------

‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á **Docker AI Services** 



![](https://paper-attachments.dropboxusercontent.com/s_7787865C7FAB426CF3D08B3DFD1DC042F998D51D6B0FF1E674EE2778F2C8DB49_1684767790083_project-Page-1.drawio+9.png)


‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÑ‡∏ß‡πâ‡∏ö‡∏ô localhost ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡πá‡∏Ñ‡πÄ‡∏õ‡πá‡∏ô docker image 
‡πÇ‡∏î‡∏¢‡∏ï‡∏±‡∏ß‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ download model ‡∏à‡∏≤‡∏Å google drive ‡∏î‡πâ‡∏ß‡∏¢ google drive api ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å model ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡πà‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ upload ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡∏ö‡∏ô google drive ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ï‡∏±‡∏ß‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å model ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏û‡∏ó‡∏¢‡πå ‡πÇ‡∏î‡∏¢ output ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô DICOM ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£ puttext ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÑ‡∏ß‡πâ ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡πÅ‡∏ö‡πà‡∏á code ‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡πÜ ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ
**‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1 :**

    def DownloadModel():
    
        # Create service
        CLIENT_SECRET_FILE = 'client_secret_75469628766-mcsp2blgek6u9g587sl6dsani4ekvpao.apps.googleusercontent.com.json'
        API_NAME = 'drive'
        API_VERSION = 'v3'
        SCOPES = ['https://www.googleapis.com/auth/drive']
        service = Create_Service(CLIENT_SECRET_FILE, API_NAME, API_VERSION, SCOPES)
    
        #Folder ID
        folder_id = '1kDl7wfNCSZcTJkIboqLk4tU1g72G9TC2'
    
        # Call the API to fetch the latest files.
        query = f"parents='{folder_id}' and mimeType!='application/vnd.google-apps.folder' and trashed=false"
        results = service.files().list(q=query, orderBy="modifiedTime desc",pageSize=1, fields="nextPageToken, files(id, name, mimeType, createdTime, modifiedTime)").execute()
    
        # check file name
        items = results.get('files', [])
    
        if not items:
            print('No files found.')
        else:
            print('Files:')
            for item in items:
                print(f"{item['name']} ({item['mimeType']}) - ID: {item['id']}")
    
        file_name = item['name']
        # print(file_name)
        file_id = item['id']
        # print(file_id)
    
        # Create folder
        folder = 'model'
        os.makedirs(folder, exist_ok=True)
    
        # Check the files in the folder
        file_list = os.listdir(folder)
        if file_list:
            for filename in file_list:
                if filename == file_name:
                    print(f"{file_name} exists in the folder.")
                    modelpath = f'{folder}/{file_name}'
                    break
            else:
                print(f"{file_name} in the folder could not be found.")
        else:
            print(f"The file in the {folder} could not be found.")
    
            # Request the file content
            print(f'Downloading...{file_name}...')
            try:
                request = service.files().get_media(fileId=file_id)
                file = io.BytesIO(request.execute())
    
                # Save the file content
                with open(f'{folder}/{file_name}', 'wb') as f:
                    f.write(file.getbuffer())
                print(f'Successfully downloaded file "{file_name}" from Google Drive')
                modelpath = f'{folder}/{file_name}'
            except HttpError as error:
                print(f'An error occurred: {error}')
    
        return modelpath
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***DownloadModel*** ‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î model ‡∏à‡∏≤‡∏Å google drive ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô google

 drive api ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏∑‡∏≠ ***CLIENT_SECRET_FILE*** ‡∏Å‡∏±‡∏ö ***foder id*** ‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô uploadFile 

     ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö google drive ‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå model ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ upload ‡∏Ç‡∏∂‡πâ‡∏ô

‡πÑ‡∏õ‡πÇ‡∏î‡∏¢‡∏à‡∏∞‡πÉ‡∏ä‡πâ ***Time*** ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ ***file_name*** ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö ID ‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ ***file_id*** 

    ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡πá‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î model ‡πÑ‡∏î‡πâ ‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô

‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏Å‡∏±‡∏ö model ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å google drive ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î model ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏Ñ‡πà‡∏≠‡∏¢‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡∏Ç‡πâ‡∏≤‡∏á‡∏ô‡∏≤‡∏ô ‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏≠‡∏¥‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡πÄ‡∏ô‡πá‡∏ï‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏à‡∏∂‡∏á‡∏°‡∏µ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ô‡∏µ‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢

‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2 :

    def dcm_to_arr(dcm_file):
    
        ds = dcmread(dcm_file, force=True)
        arr = ds.pixel_array
        print("test shape :",arr.shape)
        img = cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)
        
        return  img
    
    def predicttion(img_arr, model_path):
        print('Model path is:', model_path)
        # load model
        model = load_model(model_path)
        # print("max & min", np.amax(img_arr), np.amin(img_arr))
    
        #image normalization 16 bit to 8 bit 
        image_normali = mapRange(value=img_arr, inMin=np.amin(img_arr) ,inMax=np.amax(img_arr), outMin=0.0, outMax=255.0)
        # print("image normalization max & min :", np.amax(image_normali), np.amin(image_normali))
        # print("image normalization dtype:", image_normali.dtype)
        new_image = image_normali.astype(np.uint8)
        # print("image normalization new dtype:", new_image.dtype)    
    
        # image resize
        img_resize = cv2.resize(img_arr, (224, 224))
        print("resize :", img_resize.shape)
        image_reshape = img_resize.reshape(1, 224, 224, 3)
        print("reshape :", image_reshape.shape)  
       
        # predict image
        pred = model.predict(image_reshape)
        classes = ['normal', 'pneumonia']
        conf = pred[0]
        # print(conf)
        idx = np.argmax(conf)
        # print(idx)
        label = classes[idx]
        # print(label)
        labels = "{}: {:.2f}%".format(label, conf[idx] * 100)
        print(labels)
    
    
        # putText
        if idx == 0 :
            text_size = (img_arr.shape[0]/100) * 0.13
            image = cv2.putText(new_image, labels, (50, 120), 2, text_size, (0, 255, 0), cv2.LINE_4)
            image = cv2.putText(new_image, '(development version)', (50, 160), 2, 1, (0, 255, 0), cv2.FONT_HERSHEY_DUPLEX)
        elif idx ==1 :
            text_size = (img_arr.shape[0]/100) * 0.13
            image = cv2.putText(new_image, labels, (50, 120), 2, text_size, (0, 0, 255), cv2.LINE_4)
            image = cv2.putText(new_image, '(development version)', (90, 160), 2, 1, (0, 0, 255), cv2.FONT_HERSHEY_DUPLEX)
        
        return image 

‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å model ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏°‡∏µ 2 ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÜ ‡∏Ñ‡∏∑‡∏≠‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***dcm_to_arr*** ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• DICOM ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡πÑ‡∏õ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡πÑ‡∏î‡πâ ‡∏Å‡∏±‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô ***predicttion*** ‡πÄ‡∏õ‡πá‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡πà‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏≥ model ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡∏à‡∏≤‡∏Å google drive ‡∏°‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏†‡∏≤‡∏û 
‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π code ‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å :
https://github.com/anantachai352/ai-service-on-xnat-project/tree/main/ai_service

